{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUoZ34HxwVng",
    "outputId": "d1628c53-bc46-4837-9e53-48830e5a907f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.load(r\"C:\\Users\\AndreaEnrique\\Documents\\TFM_MBID_VIU\\res\\data_for_ml_all_std_force_quality\\x_for_ml.npy\")\n",
    "y = np.load(r\"C:\\Users\\AndreaEnrique\\Documents\\TFM_MBID_VIU\\res\\data_for_ml_all_std_force_quality\\y_for_ml.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_mc2Zgzizh5u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190847, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "SEED = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "_6gq6Na0zSve",
    "outputId": "fb4c5e56-eb04-4fd1-cec4-3e8196428bce",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-22 21:27:05.651382\n",
      "start random search\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.261 total time=   3.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.257 total time=   3.7s\n",
      "[CV 3/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.269 total time=   4.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.265 total time=   4.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.261 total time=   3.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.260 total time=   3.9s\n",
      "[CV 2/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.259 total time=   4.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.256 total time=   4.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.267 total time=   3.9s\n",
      "[CV 5/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.257 total time=   3.7s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.249 total time=   2.3s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.250 total time=   2.3s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.255 total time=   2.2s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.253 total time=   2.2s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.254 total time=   2.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.252 total time=   2.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.254 total time=   2.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.238 total time=   2.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.246 total time=   2.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.237 total time=   2.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.250 total time=   5.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.254 total time=   6.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.246 total time=   5.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.248 total time=   6.5s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.245 total time=   6.9s\n",
      "[CV 1/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.225 total time=  10.0s\n",
      "[CV 2/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.227 total time=   9.1s\n",
      "[CV 3/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.230 total time=   8.5s\n",
      "[CV 4/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.194 total time=  11.7s\n",
      "[CV 5/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.215 total time=  12.5s\n",
      "[CV 1/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.200 total time=   7.1s\n",
      "[CV 2/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.163 total time=   7.3s\n",
      "[CV 3/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.113 total time=   7.2s\n",
      "[CV 4/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.178 total time=   7.1s\n",
      "[CV 5/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.192 total time=   6.5s\n",
      "[CV 1/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.138 total time=   7.4s\n",
      "[CV 2/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.170 total time=   7.4s\n",
      "[CV 3/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.114 total time=   8.2s\n",
      "[CV 4/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.182 total time=   9.1s\n",
      "[CV 5/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.124 total time=  12.8s\n",
      "[CV 1/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.248 total time=   1.7s\n",
      "[CV 2/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.248 total time=   1.7s\n",
      "[CV 3/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.250 total time=   1.7s\n",
      "[CV 4/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.248 total time=   1.8s\n",
      "[CV 5/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.248 total time=   1.8s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.251 total time=   7.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.260 total time=   8.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.259 total time=   8.9s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.253 total time=   8.5s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.256 total time=   7.6s\n",
      "{'penalty': 'l1', 'loss': 'log_loss', 'alpha': 0.0001}\n",
      "precision 0.25815308517773305\n",
      "2026-01-22 21:33:33.146167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndreaEnrique\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from datetime import datetime\n",
    "\n",
    "print(datetime.now())\n",
    "\n",
    "n_iter_search = 10\n",
    "\n",
    "param_dist = {\"loss\":[\"log_loss\", \"modified_huber\", \n",
    "                     \"huber\"],\n",
    "              \"penalty\": [\"l1\", \"l2\"],\n",
    "              \"alpha\":[1e-4, 0.01, 1e-6],\n",
    "              \n",
    "}\n",
    "\n",
    "clf = SGDClassifier(max_iter=3000, random_state=SEED)\n",
    "print(\"start random search\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    clf, param_distributions=param_dist, n_iter=n_iter_search,\n",
    "    random_state=SEED, verbose=3)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(random_search.best_params_)\n",
    "model = random_search.best_estimator_\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"precision\", precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start random search\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.260 total time=   3.8s\n",
      "[CV 2/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.259 total time=   4.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.256 total time=   4.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.267 total time=   3.7s\n",
      "[CV 5/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.257 total time=   3.6s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.250 total time=   5.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.254 total time=   5.9s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.246 total time=   5.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.248 total time=   6.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.245 total time=   6.7s\n",
      "[CV 1/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.257 total time=   2.3s\n",
      "[CV 2/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.258 total time=   2.3s\n",
      "[CV 3/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.260 total time=   2.2s\n",
      "[CV 4/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.259 total time=   2.1s\n",
      "[CV 5/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.259 total time=   2.1s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.258 total time=   3.0s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.261 total time=   3.5s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.258 total time=   3.5s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.262 total time=   3.5s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.254 total time=   3.2s\n",
      "[CV 1/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.253 total time=   7.2s\n",
      "[CV 2/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.250 total time=   8.6s\n",
      "[CV 3/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.250 total time=   7.0s\n",
      "[CV 4/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.250 total time=   7.8s\n",
      "[CV 5/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.249 total time=   8.0s\n",
      "[CV 1/5] END alpha=1e-05, loss=modified_huber, penalty=l2;, score=0.213 total time=   7.0s\n",
      "[CV 2/5] END alpha=1e-05, loss=modified_huber, penalty=l2;, score=0.214 total time=   6.7s\n",
      "[CV 3/5] END alpha=1e-05, loss=modified_huber, penalty=l2;, score=0.233 total time=   6.4s\n",
      "[CV 4/5] END alpha=1e-05, loss=modified_huber, penalty=l2;, score=0.190 total time=   7.8s\n",
      "[CV 5/5] END alpha=1e-05, loss=modified_huber, penalty=l2;, score=0.211 total time=   9.8s\n",
      "{'alpha': 0.0001, 'loss': 'log_loss', 'penalty': 'l2'}\n",
      "precision 0.26441985244802146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_dist = {\"loss\":[\"log_loss\", \"modified_huber\"],\n",
    "              'penalty': ['l2'],\n",
    "              \"alpha\":[1e-4, 1e-3, 1e-5],\n",
    "              }\n",
    "\n",
    "clf = SGDClassifier(random_state=SEED)\n",
    "print(\"start random search\")\n",
    "search = GridSearchCV(clf, param_grid=param_dist, verbose=3)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "model = search.best_estimator_\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"precision\", precision_score(y_test, y_pred, average=\"micro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(r'C:\\Users\\AndreaEnrique\\Documents\\TFM_MBID_VIU\\models\\time_all_std_force_quality\\SGD_time.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.load(r\"C:\\Users\\AndreaEnrique\\Documents\\TFM_MBID_VIU\\res\\data_for_ml_all_std_force_quality_freq\\x_for_ml.npy\")\n",
    "y = np.load(r\"C:\\Users\\AndreaEnrique\\Documents\\TFM_MBID_VIU\\res\\data_for_ml_all_std_force_quality_freq\\y_for_ml.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190847, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "SEED = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-22 21:37:12.064367\n",
      "start random search\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.309 total time=   3.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.313 total time=   3.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.311 total time=   3.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.311 total time=   3.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.311 total time=   3.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.303 total time=   2.9s\n",
      "[CV 2/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.309 total time=   2.9s\n",
      "[CV 3/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.302 total time=   2.7s\n",
      "[CV 4/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.303 total time=   2.8s\n",
      "[CV 5/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.307 total time=   2.7s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.281 total time=   2.0s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.284 total time=   2.1s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.277 total time=   2.5s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.283 total time=   2.1s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.287 total time=   2.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.267 total time=   2.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.288 total time=   2.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.268 total time=   2.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.284 total time=   2.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, penalty=l2;, score=0.281 total time=   2.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.305 total time=   5.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.306 total time=   5.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.302 total time=   4.9s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.301 total time=   5.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.283 total time=   5.4s\n",
      "[CV 1/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.296 total time=  18.0s\n",
      "[CV 2/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.271 total time=  18.4s\n",
      "[CV 3/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.274 total time=  18.6s\n",
      "[CV 4/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.249 total time=  18.6s\n",
      "[CV 5/5] END alpha=1e-06, loss=log_loss, penalty=l2;, score=0.269 total time=  18.7s\n",
      "[CV 1/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.118 total time=   8.0s\n",
      "[CV 2/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.083 total time=   7.9s\n",
      "[CV 3/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.095 total time=   7.5s\n",
      "[CV 4/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.152 total time=   8.1s\n",
      "[CV 5/5] END alpha=1e-06, loss=huber, penalty=l1;, score=0.121 total time=   7.6s\n",
      "[CV 1/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.234 total time=  49.7s\n",
      "[CV 2/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.224 total time=  48.8s\n",
      "[CV 3/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.260 total time=  50.9s\n",
      "[CV 4/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.267 total time=  50.7s\n",
      "[CV 5/5] END alpha=1e-06, loss=modified_huber, penalty=l2;, score=0.232 total time=  50.7s\n",
      "[CV 1/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.278 total time=   1.7s\n",
      "[CV 2/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.283 total time=   1.7s\n",
      "[CV 3/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.278 total time=   1.8s\n",
      "[CV 4/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.282 total time=   1.7s\n",
      "[CV 5/5] END alpha=0.01, loss=huber, penalty=l2;, score=0.281 total time=   1.7s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.298 total time=   6.9s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.313 total time=   6.7s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.275 total time=   7.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.307 total time=   6.9s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.278 total time=   6.6s\n",
      "{'penalty': 'l1', 'loss': 'log_loss', 'alpha': 0.0001}\n",
      "precision 0.3147635814889336\n",
      "2026-01-22 21:45:44.587117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from datetime import datetime\n",
    "\n",
    "print(datetime.now())\n",
    "\n",
    "n_iter_search = 10\n",
    "\n",
    "param_dist = {\"loss\":[\"log_loss\", \"modified_huber\", \n",
    "                     \"huber\"],\n",
    "              \"penalty\": [\"l1\", \"l2\"],\n",
    "              \"alpha\":[1e-4, 0.01, 1e-6],\n",
    "              \n",
    "}\n",
    "\n",
    "clf = SGDClassifier(max_iter=3000, random_state=SEED)\n",
    "print(\"start random search\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    clf, param_distributions=param_dist, n_iter=n_iter_search,\n",
    "    random_state=SEED, verbose=3)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(random_search.best_params_)\n",
    "model = random_search.best_estimator_\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"precision\", precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start random search\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.303 total time=   2.8s\n",
      "[CV 2/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.309 total time=   2.7s\n",
      "[CV 3/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.302 total time=   2.6s\n",
      "[CV 4/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.303 total time=   2.7s\n",
      "[CV 5/5] END alpha=0.0001, loss=log_loss, penalty=l2;, score=0.307 total time=   2.7s\n",
      "[CV 1/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.309 total time=   3.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.313 total time=   3.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.311 total time=   3.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.311 total time=   3.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=log_loss, penalty=l1;, score=0.311 total time=   3.3s\n",
      "[CV 1/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.295 total time=   2.0s\n",
      "[CV 2/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.297 total time=   2.0s\n",
      "[CV 3/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.295 total time=   2.0s\n",
      "[CV 4/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.297 total time=   2.0s\n",
      "[CV 5/5] END alpha=0.001, loss=log_loss, penalty=l2;, score=0.299 total time=   2.0s\n",
      "[CV 1/5] END alpha=0.001, loss=log_loss, penalty=l1;, score=0.296 total time=   2.5s\n",
      "[CV 2/5] END alpha=0.001, loss=log_loss, penalty=l1;, score=0.299 total time=   2.6s\n",
      "[CV 3/5] END alpha=0.001, loss=log_loss, penalty=l1;, score=0.296 total time=   2.6s\n",
      "[CV 4/5] END alpha=0.001, loss=log_loss, penalty=l1;, score=0.298 total time=   2.6s\n",
      "[CV 5/5] END alpha=0.001, loss=log_loss, penalty=l1;, score=0.300 total time=   2.6s\n",
      "[CV 1/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.294 total time=   5.6s\n",
      "[CV 2/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.303 total time=   5.7s\n",
      "[CV 3/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.289 total time=   5.8s\n",
      "[CV 4/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.303 total time=   5.8s\n",
      "[CV 5/5] END alpha=1e-05, loss=log_loss, penalty=l2;, score=0.302 total time=   5.8s\n",
      "[CV 1/5] END alpha=1e-05, loss=log_loss, penalty=l1;, score=0.309 total time=   6.9s\n",
      "[CV 2/5] END alpha=1e-05, loss=log_loss, penalty=l1;, score=0.307 total time=   6.8s\n",
      "[CV 3/5] END alpha=1e-05, loss=log_loss, penalty=l1;, score=0.296 total time=   7.0s\n",
      "[CV 4/5] END alpha=1e-05, loss=log_loss, penalty=l1;, score=0.307 total time=   6.9s\n",
      "[CV 5/5] END alpha=1e-05, loss=log_loss, penalty=l1;, score=0.300 total time=   6.9s\n",
      "{'alpha': 0.0001, 'loss': 'log_loss', 'penalty': 'l1'}\n",
      "precision 0.3147635814889336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_dist = {\"loss\":[\"log_loss\"],\n",
    "              'penalty': ['l2', \"l1\"],\n",
    "              \"alpha\":[1e-4, 1e-3, 1e-5],\n",
    "              }\n",
    "\n",
    "clf = SGDClassifier(random_state=SEED)\n",
    "print(\"start random search\")\n",
    "search = GridSearchCV(clf, param_grid=param_dist, verbose=3)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "model = search.best_estimator_\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"precision\", precision_score(y_test, y_pred, average=\"micro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(r'C:\\Users\\AndreaEnrique\\Documents\\TFM_MBID_VIU\\models\\freq_all_std_force_quality\\SGD_freq.pickle', 'wb') as f:\n",
    "\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
